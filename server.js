const express = require('express');
const fs = require('fs').promises;
const path = require('path');
const multer = require('multer');
const AdmZip = require('adm-zip');

const app = express();
const PORT = 3000;

// Multer configuration
const upload = multer({ 
  dest: 'uploads/',
  limits: { fileSize: 50 * 1024 * 1024 } // 50MB limit
});

// Serve static files
app.use(express.static('public'));
app.use(express.json());

// Extract fields from document.xml
function extractFields(xmlContent) {
  const fieldPattern = /\{([^}]+)\}/g;
  const fields = new Set();
  let match;
  
  while ((match = fieldPattern.exec(xmlContent)) !== null) {
    let field = match[1].trim();
    
    // Clean logical constructions like analyzer.js does
    // Remove Ñ†Ð¸ÐºÐ»(x Ð¸Ð· ÑÐ¿Ð¸ÑÐ¾Ðº) -> ÑÐ¿Ð¸ÑÐ¾Ðº
    field = field.replace(/Ñ†Ð¸ÐºÐ»\([^)]+Ð¸Ð·\s+([^)]+)\)/gi, '$1');
    // Remove Ð²Ñ‹Ð±Ð¾Ñ€(...) wrapper
    field = field.replace(/Ð²Ñ‹Ð±Ð¾Ñ€\((.+)\)/gi, '$1');
    // Remove ÐµÑÐ»Ð¸(...) wrapper  
    field = field.replace(/ÐµÑÐ»Ð¸\((.+)\)/gi, '$1');
    
    // Extract content from parentheses: Ñ„ÑƒÐ½ÐºÑ†Ð¸Ñ(ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ð¼Ð¾Ðµ) -> ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ð¼Ð¾Ðµ
    const lastParen = field.lastIndexOf('(');
    if (lastParen > 0) {
      const closeParen = field.lastIndexOf(')');
      if (closeParen > lastParen) {
        field = field.substring(lastParen + 1, closeParen);
      } else {
        // No closing paren, take everything after opening
        field = field.substring(lastParen + 1);
          }
    field = field.trim();}
    if (field) { fields.add(field);
    }
  }
  
  return Array.from(fields).sort();
}

// Extract prefixes from fields
function extractPrefixes(fields) {
  const prefixes = new Set();
  
  fields.forEach(field => {
    // Extract prefix before first dot
    const dotIndex = field.indexOf('.');
    if (dotIndex > 0) {
      const prefix = field.substring(0, dotIndex);
      prefixes.add(prefix);
    }
  });
  
  return Array.from(prefixes).sort();
}

// Upload and analyze file
app.post('/api/upload-and-analyze', upload.single('file'), async (req, res) => {
  try {
    if (!req.file) {
      return res.status(400).json({ 
        success: false, 
        message: 'âŒ Ð¤Ð°Ð¹Ð» Ð½Ðµ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½' 
      });
    }

    const filePath = req.file.path;
    let documentXml = null;

    try {
      // Open ZIP archive (.docx or .fdt)
      const zip = new AdmZip(filePath);
      const zipEntries = zip.getEntries();
      
      // Check if this is a .fdt file (contains template.docx)
      const isFdt = zipEntries.some(entry => entry.entryName === 'template.docx');
      
      let xmlEntry = null;
      
      if (isFdt) {
        // For .fdt: extract template.docx and then get word/document.xml from it
        const templateEntry = zipEntries.find(entry => entry.entryName === 'template.docx');
        if (templateEntry) {
          const templateZip = new AdmZip(templateEntry.getData());
          xmlEntry = templateZip.getEntries().find(entry => entry.entryName === 'word/document.xml');
          if (xmlEntry) {
            documentXml = xmlEntry.getData().toString('utf8');
          }
        }
      } else {
        // For .docx: directly get word/document.xml
        xmlEntry = zipEntries.find(entry => entry.entryName === 'word/document.xml');
        if (xmlEntry) {
          documentXml = xmlEntry.getData().toString('utf8');
        }
      }
      
      if (!documentXml) {
        return res.status(400).json({
          success: false,
          message: 'âŒ document.xml Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½ Ð² Ð°Ñ€Ñ…Ð¸Ð²Ðµ'
        });
      }    } finally {
      // Clean up uploaded file
      await fs.unlink(filePath).catch(() => {});
    }
    
    // Extract fields
    const fields = extractFields(documentXml);
    const prefixes = extractPrefixes(fields);
    
    res.json({
      success: true,
      fields: fields,
      prefixes: prefixes,
      totalFields: fields.length,
      totalPrefixes: prefixes.length
    });
    
  } catch (error) {
    console.error('Error:', error);
    res.status(500).json({ 
      success: false, 
      message: 'âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ Ñ„Ð°Ð¹Ð»Ð°' 
    });
  }
});

// Generate config.json
app.post('/api/generate-config', async (req, res) => {
  try {
    const { fileName, oldPrefix, newPrefix } = req.body;
    
    // Validation
    if (!fileName || !oldPrefix || !newPrefix) {
      return res.status(400).json({ 
        success: false, 
        message: 'âŒ ÐÐµ Ð²ÑÐµ Ð¿Ð¾Ð»Ñ Ð·Ð°Ð¿Ð¾Ð»Ð½ÐµÐ½Ñ‹' 
      });
    }
    
    if (oldPrefix === newPrefix) {
      return res.status(400).json({ 
        success: false, 
        message: 'âš ï¸ ÐŸÑ€ÐµÑ„Ð¸ÐºÑÑ‹ Ð½Ðµ Ð´Ð¾Ð»Ð¶Ð½Ñ‹ ÑÐ¾Ð²Ð¿Ð°Ð´Ð°Ñ‚ÑŒ' 
      });
    }
    
    // Generate config
    const config = {
      "analyzer": {
        "inputFile": "IN/document.xml",
        "outputFile": "OUT/unique_names.json",
        "originalPrefix": oldPrefix + ".",
        "cleanLogicalConstructions": true,
        "sortByLength": true
      },
      "generator": {
        "inputFile": "OUT/unique_names.json",
        "outputFile": "OUT/replacement_map.json",
        "newPrefix": newPrefix + ".",
        "encoding": "utf8"
      },
      "replacer": {
        "inputFile": "IN/document.xml",
        "outputFile": "OUT/document.xml",
        "replacementMapFile": "OUT/replacement_map.json"
      }
    };
    
    // Save config.json
    const configPath = path.join(__dirname, 'config.json');
    await fs.writeFile(
      configPath, 
      JSON.stringify(config, null, 2), 
      'utf8'
    );
    
    res.json({ 
      success: true, 
      message: 'âœ… ÐšÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ñ ÑÐ¾Ð·Ð´Ð°Ð½Ð°',
      filePath: 'config.json'
    });
    
  } catch (error) {
    console.error('Error:', error);
    res.status(500).json({ 
      success: false, 
      message: 'âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ð¸ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¸' 
    });
  }
});

app.listen(PORT, () => {
  console.log(`ðŸ”„ Replacer-2 Ð·Ð°Ð¿ÑƒÑ‰ÐµÐ½ Ð½Ð° http://localhost:${PORT}`);
});
